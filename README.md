# Projeto ETL de Dados da FÃ³rmula 1

![Python](https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-14-336791?style=for-the-badge&logo=postgresql)
![Pandas](https://img.shields.io/badge/Pandas-1.5.3-150458?style=for-the-badge&logo=pandas)
![SQLAlchemy](https://img.shields.io/badge/SQLAlchemy-2.0-d71f00?style=for-the-badge&logo=sqlalchemy)

## ğŸ“œ DescriÃ§Ã£o

Este projeto consiste em um pipeline de ETL (ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga) automatizado, desenvolvido em Python. [cite_start]Ele foi projetado para extrair dados de corridas de FÃ³rmula 1 de um conjunto de arquivos CSV, processÃ¡-los e carregÃ¡-los em um banco de dados relacional PostgreSQL. [cite_start]O objetivo final Ã© disponibilizar esses dados de forma estruturada atravÃ©s de views no banco, prontas para serem consumidas por ferramentas de relatÃ³rios e anÃ¡lise.

[cite_start]Os dados sÃ£o uma amostra do conjunto de dados pÃºblico **Ergast**, disponibilizados em um repositÃ³rio especÃ­fico no GitHub para este desafio.

## âœ¨ Funcionalidades

-   **ExtraÃ§Ã£o:** Download automÃ¡tico dos arquivos CSV de URLs especificadas. [cite_start]O script cria a pasta de destino e verifica hashes MD5 para evitar downloads repetidos e desnecessÃ¡rios.
-   **TransformaÃ§Ã£o:** Processamento dos dados brutos com a biblioteca Pandas, incluindo:
    -   SeleÃ§Ã£o de colunas relevantes.
    -   CriaÃ§Ã£o de novas colunas (ex: `fullname` a partir de `forename` e `surname`).
    -   Ajuste e garantia da consistÃªncia dos tipos de dados.
-   **Carga:** Carregamento dos dados transformados em um banco de dados PostgreSQL. O script garante a idempotÃªncia, limpando as tabelas antes de cada carga para evitar duplicidade.
-   **Banco de Dados:** CriaÃ§Ã£o de tabelas e views SQL para responder a perguntas de negÃ³cio especÃ­ficas, como:
    -   O resultado de cada corredor por ano (vitÃ³rias e pontos).
    -   O piloto com a volta mais rÃ¡pida para cada Grande PrÃªmio.
-   **Explorador de Dados:** Um script interativo (`main_data_explorer.py`) para inspecionar e verificar os dados brutos e transformados diretamente no terminal.

## ğŸ› ï¸ Tecnologias Utilizadas

-   **Linguagem:** Python 3.12
-   **Banco de Dados:** PostgreSQL 14
-   **Principais Bibliotecas Python:**
    -   `pandas`: Para manipulaÃ§Ã£o e transformaÃ§Ã£o de dados.
    -   `requests`: Para o download dos arquivos.
    -   `SQLAlchemy` e `psycopg2`: Para a interaÃ§Ã£o com o banco de dados PostgreSQL.
    -   `python-dotenv`: Para gerenciamento de variÃ¡veis de ambiente e credenciais.

## ğŸ—‚ï¸ Estrutura do Projeto

```
formula1_etl/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py             # ConfiguraÃ§Ãµes centrais
â”œâ”€â”€ data_extraction/
â”‚   â””â”€â”€ extractor.py            # MÃ³dulo de extraÃ§Ã£o de dados
â”œâ”€â”€ data_exploration/
â”‚   â””â”€â”€ explorer.py             # MÃ³dulo de exploraÃ§Ã£o de dados
â”œâ”€â”€ data_transformation/
â”‚   â””â”€â”€ transformer.py          # MÃ³dulo de transformaÃ§Ã£o de dados
â”œâ”€â”€ data_loading/
â”‚   â””â”€â”€ loader.py               # MÃ³dulo de carga de dados
â”œâ”€â”€ sql_scripts/
â”‚   â”œâ”€â”€ create_tables.sql       # Script de criaÃ§Ã£o das tabelas
â”‚   â””â”€â”€ create_views.sql        # Script de criaÃ§Ã£o das views
â”œâ”€â”€ .env.example                # Arquivo de exemplo para variÃ¡veis de ambiente
â”œâ”€â”€ .gitignore                  # Arquivos a serem ignorados pelo Git
â”œâ”€â”€ main_data_explorer.py       # Ponto de entrada para explorar dados
â”œâ”€â”€ main_etl_pipeline.py        # Ponto de entrada para executar o ETL
â””â”€â”€ README.md                   # Este arquivo
```

## âš™ï¸ PrÃ©-requisitos

Antes de comeÃ§ar, garanta que vocÃª tenha os seguintes softwares instalados em sua mÃ¡quina:
-   [Python](https://www.python.org/downloads/) (versÃ£o 3.9 ou superior)
-   [Git](https://git-scm.com/downloads/)
-   [PostgreSQL](https://www.postgresql.org/download/) (versÃ£o 12 ou superior)

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

Siga estes passos para configurar o ambiente e executar o projeto.

### 1. Clonar o RepositÃ³rio
```bash
git clone <URL_DO_SEU_REPOSITORIO_AQUI>
cd formula1_etl
```

### 2. Configurar o Banco de Dados PostgreSQL

Esta Ã© a etapa mais crÃ­tica. O script precisa se conectar a um banco de dados que jÃ¡ exista.

1.  **Instale o PostgreSQL** caso ainda nÃ£o o tenha. Durante a instalaÃ§Ã£o, defina uma senha para o superusuÃ¡rio `postgres`.
2.  **Abra o pgAdmin** (ou outro cliente SQL) e crie um novo banco de dados.
    -   **Nome do Banco:** `formula1_db`
    -   **CodificaÃ§Ã£o (Encoding):** **`UTF8`** (extremamente importante para evitar erros).
3.  **Crie as Tabelas e Views:**
    -   Ainda no pgAdmin, conectado ao banco `formula1_db`, abra a ferramenta de consulta (Query Tool).
    -   Copie o conteÃºdo do arquivo `sql_scripts/create_tables.sql` e execute-o.
    -   Em seguida, copie o conteÃºdo de `sql_scripts/create_views.sql` e execute-o.

### 3. Configurar VariÃ¡veis de Ambiente

1.  Crie uma cÃ³pia do arquivo `.env.example` e renomeie-a para `.env`.
    ```bash
    # No Windows (usando PowerShell ou cmd)
    copy .env.example .env
    ```
2.  Abra o arquivo `.env` e preencha com as suas credenciais do PostgreSQL.
    ```ini
    # .env
    DB_HOST=localhost
    DB_PORT=5432
    DB_NAME=formula1_db
    DB_USER=postgres
    DB_PASSWORD=sua_senha_aqui 
    DB_TYPE=postgresql
    # ... outras variÃ¡veis
    ```

### 4. Configurar o Ambiente Python

Ã‰ uma boa prÃ¡tica usar um ambiente virtual (`venv`).

1.  **Crie o ambiente virtual:**
    ```bash
    python -m venv .venv
    ```
2.  **Ative o ambiente:**
    ```bash
    # No Windows (PowerShell)
    .\.venv\Scripts\Activate.ps1
    # No Windows (cmd)
    .\.venv\Scripts\activate.bat
    ```
3.  **Instale as dependÃªncias:**
    ```bash
    pip install -r requirements.txt
    ```

## â–¶ï¸ Executando o Projeto

Com tudo configurado, vocÃª pode executar os scripts principais.

### Executar o Pipeline ETL Completo
Para extrair, transformar e carregar todos os dados no banco de dados:
```bash
python main_etl_pipeline.py
```

### Executar o Explorador de Dados
Para analisar os dados brutos ou transformados de forma interativa pelo terminal:
```bash
python main_data_explorer.py
```

## âœ… VerificaÃ§Ã£o

ApÃ³s a execuÃ§Ã£o bem-sucedida do pipeline, vocÃª pode verificar o resultado final diretamente no banco de dados. Conecte-se ao `formula1_db` com o pgAdmin e execute as seguintes consultas:

```sql
-- Consultar os resultados da View 1 (pilotos por ano)
SELECT * FROM view_driver_yearly_results LIMIT 20;

-- Consultar os resultados da View 2 (voltas mais rÃ¡pidas)
SELECT * FROM view_grand_prix_fastest_laps LIMIT 20;
```
Os resultados devem corresponder Ã s saÃ­das de exemplo fornecidas na especificaÃ§Ã£o do projeto.

---
## âœï¸ Autor

**Matheus Romero Rodrigues Marinho**

-   [LinkedIn](Linkedin.com/in/matheusmrinho)
-   [GitHub](github.com/matheusmrinho)
